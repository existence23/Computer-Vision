function [out, act_h, act_a] = Forward(W, b, X)
% [OUT, act_h, act_a] = Forward(W, b, X) performs forward propogation on the
% input data 'X' uisng the network defined by weights and biases 'W' and 'b'
% (as generated by InitializeNetwork(..)).
%
% This function should return the final softmax output layer activations in OUT,
% as well as the hidden layer post activations in 'act_h', and the hidden layer
% pre activations in 'act_a'.

act_a = cell(1, length(W));
act_h = cell(1, length(W));

for i = 1:length(W)
    if i == 1
        act_a{i} = W{i} * X' + b{i}; %X 1xN
    else
        act_a{i} = W{i} * act_h{i-1} + b{i};
    end
    act_a{i}(isnan(act_a{i})) = 0;
    
    if i < length(W)
        act_h{i} = sigmf(act_a{i}, [1 0]);
    else
        a = act_a{i};
        act_h{i} = (exp(a)) / sum(exp(a));
    end
    act_h{i}(isnan(act_h{i})) = 0;
end

out = act_h{length(W)};



end
